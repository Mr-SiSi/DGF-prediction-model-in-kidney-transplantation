{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, roc_curve, auc, precision_recall_curve, \n",
    "                             confusion_matrix, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "dataset = pd.read_csv('C:/Users/Administrator/OneDrive/help/评分模型/dataset/dataset.CSV', encoding=\"ANSI\")\n",
    "\n",
    "# 显示数据基本信息\n",
    "print(\"数据集基本信息：\")\n",
    "print(dataset.info())\n",
    "\n",
    "print(\"\\n缺失值统计：\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# 选择需要填充的数值列\n",
    "numeric_columns = dataset.select_dtypes(include=[np.number]).columns\n",
    "print(numeric_columns)\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv('C:/Users/Administrator/OneDrive/help/评分模型/dataset/dataset.CSV', encoding=\"ANSI\")\n",
    "\n",
    "# 显示数据基本信息\n",
    "print(\"数据集基本信息：\")\n",
    "print(dataset.info())\n",
    "\n",
    "print(\"\\n缺失值统计：\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# 选择需要填充的数值列\n",
    "numeric_columns = dataset.select_dtypes(include=[np.number]).columns\n",
    "print(numeric_columns)\n",
    "\n",
    "# 使用IterativeImputer填充\n",
    "it_imputer = IterativeImputer(estimator=RandomForestRegressor(), random_state=0)\n",
    "dataset_imputed_it = dataset.copy()\n",
    "dataset_imputed_it[numeric_columns] = it_imputer.fit_transform(dataset[numeric_columns])\n",
    "\n",
    "print(\"\\n使用IterativeImputer填充后的数据集：\")\n",
    "print(dataset_imputed_it.info())\n",
    "print(dataset_imputed_it.isnull().sum())\n",
    "\n",
    "# 使用KNNImputer填充\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "dataset_imputed_knn = dataset.copy()\n",
    "dataset_imputed_knn[numeric_columns] = knn_imputer.fit_transform(dataset[numeric_columns])\n",
    "\n",
    "print(\"\\n使用KNNImputer填充后的数据集：\")\n",
    "print(dataset_imputed_knn.info())\n",
    "print(dataset_imputed_knn.isnull().sum())\n",
    "\n",
    "# 保存填充后的数据集\n",
    "dataset_imputed_it.to_csv('dataset_imputed_iterative.csv', index=False, encoding='ANSI')\n",
    "dataset_imputed_knn.to_csv('dataset_imputed_knn.csv', index=False, encoding='ANSI')\n",
    "\n",
    "print(\"\\n填充后的数据集已保存为 'dataset_imputed_iterative.csv' 和 'dataset_imputed_knn.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:/Users/Administrator/OneDrive/help/评分模型/dataset_imputed_iterative.CSV',encoding = \"ANSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9cf46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29bd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ba959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[\"DGF\"].describe()\n",
    "dataset[\"DGF\"].unique()\n",
    "print(dataset.corr()[\"DGF\"].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26079eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 加载和预处理数据\n",
    "# Load dataset\n",
    "df = dataset  # Make sure you have a DataFrame named 'dataset'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('DGF', axis=1)\n",
    "y = df['DGF']\n",
    "\n",
    "print(f\"Positive class percentage: {y.mean()*100:.2f}%\")\n",
    "\n",
    "# Apply RandomUnderSampler to the entire dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "print(f\"Positive class percentage after resampling: {y_resampled.mean()*100:.2f}%\")\n",
    "\n",
    "# Standardizing the feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# 这个cell加载数据集，分离特征和目标变量，应用随机欠采样来平衡类别，\n",
    "# 并对特征进行标准化。它还打印了正类的百分比，以显示重采样前后的类别分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25105c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 定义优化函数\n",
    "def optimize_logistic_regression(X, y):\n",
    "    param_space = {\n",
    "        'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "        'penalty': Categorical(['l1', 'l2'])\n",
    "    }\n",
    "    \n",
    "    optimizer = BayesSearchCV(\n",
    "        LogisticRegression(random_state=42, solver='liblinear'),\n",
    "        param_space,\n",
    "        n_iter=20,\n",
    "        cv=4,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        scoring='roc_auc'\n",
    "    )\n",
    "    \n",
    "    optimizer.fit(X, y)\n",
    "    return optimizer.best_estimator_\n",
    "\n",
    "def optimize_random_forest(X, y):\n",
    "    param_space = {\n",
    "        'n_estimators': Integer(10, 200),\n",
    "        'max_depth': Integer(2, 20),\n",
    "        'min_samples_split': Integer(2, 10),\n",
    "        'min_samples_leaf': Integer(1, 10)\n",
    "    }\n",
    "    \n",
    "    optimizer = BayesSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_space,\n",
    "        n_iter=20,\n",
    "        cv=4,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        scoring='roc_auc'\n",
    "    )\n",
    "    \n",
    "    optimizer.fit(X, y)\n",
    "    return optimizer.best_estimator_\n",
    "\n",
    "# 这个cell定义了两个优化函数，分别用于逻辑回归和随机森林模型。\n",
    "# 这些函数使用贝叶斯搜索来优化模型的超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fa4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 初始化模型\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Neural Network': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# 这个cell初始化了所有要测试的模型，并将它们存储在一个字典中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 定义评估指标计算函数\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    return accuracy, precision, recall, f1, specificity, roc_auc, pr_auc, fpr, tpr, precision_curve, recall_curve\n",
    "\n",
    "# 这个cell定义了一个函数，用于计算各种评估指标，包括准确率、精确率、召回率、F1分数、\n",
    "# 特异性、ROC AUC和PR AUC等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 训练模型\n",
    "# 假设dataset已经加载,并且'DGF'是目标变量\n",
    "X = dataset.drop('DGF', axis=1)\n",
    "y = dataset['DGF']\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 初始化模型\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Neural Network': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# 70%训练, 30%测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 创建一个图表来存储所有ROC曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 为每个模型计算并绘制ROC曲线\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    print(f\"{name} - 70-30 split ROC-AUC: {roc_auc:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f\"AUC.pdf\", format=\"pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: cross-validation\n",
    "# 10倍交叉验证\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 存储结果的字典\n",
    "results = {\n",
    "    'Accuracy': [],\n",
    "    'ROC-AUC': []\n",
    "}\n",
    "\n",
    "# 为每个模型进行交叉验证\n",
    "for name, model in models.items():\n",
    "    accuracies = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "    roc_aucs = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_roc_auc = np.mean(roc_aucs)\n",
    "    \n",
    "    results['Accuracy'].append(mean_accuracy)\n",
    "    results['ROC-AUC'].append(mean_roc_auc)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  10-fold CV Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"  10-fold CV Mean ROC-AUC: {mean_roc_auc:.4f}\")\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 准确率折线图\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(list(models.keys()), results['Accuracy'], marker='o')\n",
    "plt.title('Mean Accuracy for Different Models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "\n",
    "# ROC-AUC折线图\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(list(models.keys()), results['ROC-AUC'], marker='o')\n",
    "plt.title('Mean ROC-AUC for Different Models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean ROC-AUC')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"10-fold cross validation.pdf\", format=\"pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: 保存训练好的模型\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = []\n",
    "    for model in models.values():\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            pred = model.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            pred = model.predict(X)\n",
    "        predictions.append(pred)\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# Cell 10: 保存集成模型\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# 确保存在保存模型的目录\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')\n",
    "\n",
    "# 保存各个模型\n",
    "for model_name, model in models.items():\n",
    "    filename = f'saved_models/{model_name.replace(\" \", \"_\").lower()}.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f'{model_name} 已保存为 {filename}')\n",
    "\n",
    "# 保存集成函数和模型字典\n",
    "ensemble_package = {\n",
    "    'ensemble_function': ensemble_predict,\n",
    "    'models': models\n",
    "}\n",
    "\n",
    "with open('saved_models/ensemble_model.pkl', 'wb') as file:\n",
    "    pickle.dump(ensemble_package, file)\n",
    "\n",
    "print(\"集成模型已保存为 saved_models/ensemble_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 初始化模型\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Neural Network': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)  # 设置verbose=-1来抑制警告\n",
    "}\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'specificity': make_scorer(specificity_score)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': np.mean(cv_results['test_accuracy']),\n",
    "        'ROC AUC Mean': np.mean(cv_results['test_roc_auc']),\n",
    "        'ROC AUC Std': np.std(cv_results['test_roc_auc']),\n",
    "        'Precision': np.mean(cv_results['test_precision']),\n",
    "        'Recall': np.mean(cv_results['test_recall']),\n",
    "        'F1 Score': np.mean(cv_results['test_f1']),\n",
    "        'Specificity': np.mean(cv_results['test_specificity'])\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
    "df_results = df_results[['ROC AUC Mean', 'ROC AUC Std', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Specificity']]\n",
    "\n",
    "print(\"Model Performance Metrics (10-Fold Cross-Validation):\")\n",
    "print(df_results.to_string(float_format=lambda x: f\"{x:.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 初始化三个模型\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'specificity': make_scorer(specificity_score)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': np.mean(cv_results['test_accuracy']),\n",
    "        'ROC AUC Mean': np.mean(cv_results['test_roc_auc']),\n",
    "        'ROC AUC Std': np.std(cv_results['test_roc_auc']),\n",
    "        'Precision': np.mean(cv_results['test_precision']),\n",
    "        'Recall': np.mean(cv_results['test_recall']),\n",
    "        'F1 Score': np.mean(cv_results['test_f1']),\n",
    "        'Specificity': np.mean(cv_results['test_specificity'])\n",
    "    }\n",
    "\n",
    "df_cv_results = pd.DataFrame.from_dict(results, orient='index')\n",
    "df_cv_results = df_cv_results[['ROC AUC Mean', 'ROC AUC Std', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Specificity']]\n",
    "\n",
    "print(\"模型性能指标（10倍交叉验证）:\")\n",
    "print(df_cv_results.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# 加载外部测试数据（单个样本）\n",
    "test_df = pd.read_csv('C:/Users/Administrator/OneDrive/help/评分模型/dataset/test.CSV', encoding=\"ANSI\")\n",
    "\n",
    "# 分离特征和标准结果（如果有）\n",
    "if test_df.shape[1] > len(X.columns):\n",
    "    y_true = test_df.iloc[0, 0]  # 假设第一列是DGF的标准结果\n",
    "    test_X = test_df.iloc[0, 1:]  # 其余列是特征\n",
    "else:\n",
    "    y_true = None\n",
    "    test_X = test_df.iloc[0, :]  # 所有列都是特征\n",
    "\n",
    "# 确保测试数据集的特征与训练数据集相同\n",
    "test_X = test_X[X.columns]\n",
    "\n",
    "# 标准化测试数据\n",
    "test_X_scaled = scaler.transform(test_X.values.reshape(1, -1))\n",
    "\n",
    "# 创建一个字典来存储测试集结果\n",
    "test_results = {}\n",
    "\n",
    "# 在外部测试集上评估模型\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} 对单个样本的预测结果:\")\n",
    "    \n",
    "    # 使用全部训练数据重新训练模型\n",
    "    model.fit(X_scaled, y)\n",
    "    y_pred = model.predict(test_X_scaled)\n",
    "    y_pred_proba = model.predict_proba(test_X_scaled)[0, 1]\n",
    "\n",
    "    print(f\"预测结果: {'正' if y_pred[0] == 1 else '负'}\")\n",
    "    print(f\"预测概率 (正类别): {y_pred_proba:.4f}\")\n",
    "\n",
    "    if y_true is not None:\n",
    "        print(f\"实际结果: {'正' if y_true == 1 else '负'}\")\n",
    "\n",
    "    test_results[name] = {\n",
    "        'Predicted': '正' if y_pred[0] == 1 else '负',\n",
    "        'Probability': y_pred_proba\n",
    "    }\n",
    "\n",
    "# 创建测试集结果DataFrame\n",
    "df_test_results = pd.DataFrame.from_dict(test_results, orient='index')\n",
    "\n",
    "print(\"\\n模型预测结果汇总:\")\n",
    "print(df_test_results.to_string(float_format=lambda x: f\"{x:.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 初始化三个模型\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'specificity': make_scorer(specificity_score)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': np.mean(cv_results['test_accuracy']),\n",
    "        'ROC AUC Mean': np.mean(cv_results['test_roc_auc']),\n",
    "        'ROC AUC Std': np.std(cv_results['test_roc_auc']),\n",
    "        'Precision': np.mean(cv_results['test_precision']),\n",
    "        'Recall': np.mean(cv_results['test_recall']),\n",
    "        'F1 Score': np.mean(cv_results['test_f1']),\n",
    "        'Specificity': np.mean(cv_results['test_specificity'])\n",
    "    }\n",
    "\n",
    "df_cv_results = pd.DataFrame.from_dict(results, orient='index')\n",
    "df_cv_results = df_cv_results[['ROC AUC Mean', 'ROC AUC Std', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Specificity']]\n",
    "\n",
    "print(\"模型性能指标（10倍交叉验证）:\")\n",
    "print(df_cv_results.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# 加载外部测试数据\n",
    "test_df = pd.read_csv('C:/Users/Administrator/OneDrive/help/评分模型/dataset/test2.CSV', encoding=\"ANSI\")\n",
    "\n",
    "# 分离特征和标准结果\n",
    "y_true = test_df.iloc[:, 0]  # 假设第一列是DGF的标准结果\n",
    "test_X = test_df.iloc[:, 1:]  # 其余列是特征\n",
    "\n",
    "# 确保测试数据集的特征与训练数据集相同\n",
    "test_X = test_X[X.columns]\n",
    "\n",
    "# 标准化测试数据\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "# 创建一个字典来存储测试集结果\n",
    "test_results = {}\n",
    "\n",
    "# 创建一个图来绘制所有ROC曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 在外部测试集上评估模型\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} 在外部测试集上的表现:\")\n",
    "    \n",
    "    # 使用全部训练数据重新训练模型\n",
    "    model.fit(X, y)  # 这些模型不需要标准化的数据\n",
    "    y_pred = model.predict(test_X)\n",
    "    y_pred_proba = model.predict_proba(test_X)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    test_results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Specificity': specificity_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # 绘制ROC曲线\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# 完成ROC曲线图\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - All Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f\"ROC-test.pdf\", format=\"pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 创建测试集结果DataFrame\n",
    "df_test_results = pd.DataFrame.from_dict(test_results, orient='index')\n",
    "df_test_results = df_test_results[['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Specificity']]\n",
    "\n",
    "print(\"\\n模型性能指标（测试集）:\")\n",
    "print(df_test_results.to_string(float_format=lambda x: f\"{x:.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a23389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 确保 X 和 models 字典已经定义\n",
    "\n",
    "shap_values_dict = {}\n",
    "\n",
    "# 对XGBoost和LightGBM计算SHAP值\n",
    "for model_name in ['XGBoost', 'LightGBM']:\n",
    "    model = models[model_name]\n",
    "    \n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    # 对于XGBoost和LightGBM，shap_values通常已经是我们需要的形式\n",
    "    # 但是为了保险起见，我们还是检查一下\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # 对于二分类问题，我们通常关注正类\n",
    "    \n",
    "    shap_values_dict[model_name] = shap_values\n",
    "\n",
    "# 绘制详细的SHAP值图\n",
    "for model_name, shap_values in shap_values_dict.items():\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X, show=False)\n",
    "    plt.title(f'{model_name} SHAP Summary Plot')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_shap_summary.pdf\", format=\"pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 计算和打印平均绝对SHAP值\n",
    "for model_name, shap_values in shap_values_dict.items():\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    feature_importance = pd.DataFrame(list(zip(X.columns, mean_abs_shap)), columns=['feature', 'importance'])\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{model_name} 特征重要性 (基于平均绝对SHAP值):\")\n",
    "    print(feature_importance.to_string(index=False))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
